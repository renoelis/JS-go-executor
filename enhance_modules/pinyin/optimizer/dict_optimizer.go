package optimizer

import (
	"flow-codeblock-go/enhance_modules/pinyin/dict"
	"flow-codeblock-go/enhance_modules/pinyin/postag"
	"flow-codeblock-go/enhance_modules/pinyin/tokenizer"
)

// DictOptimizer è¯å…¸ä¼˜åŒ–å™¨
// å®ç°ç±»ä¼¼ MMSG (æœ€å¤§åŒ¹é…-æœ€çŸ­è·¯å¾„-è¯è¯­ç²˜è¿) ç®—æ³•
// ä¸»è¦åŠŸèƒ½ï¼š
// 1. åˆå¹¶è¿ç»­çš„å•å­—è¯ä¸ºè¯ç»„
// 2. ä¼˜åŒ–è¯è¯­è¾¹ç•Œ
// 3. æé«˜åˆ†è¯è´¨é‡
//
// ä¸ JavaScript pinyin.js çš„ DictOptimizer å…¼å®¹
type DictOptimizer struct{}

// NewDictOptimizer åˆ›å»ºè¯å…¸ä¼˜åŒ–å™¨
func NewDictOptimizer() *DictOptimizer {
	// ç¡®ä¿å­—å…¸å·²åŠ è½½
	dict.Init()
	return &DictOptimizer{}
}

// Optimize å®ç° Optimizer æ¥å£
func (o *DictOptimizer) Optimize(words []tokenizer.Word) []tokenizer.Word {
	if len(words) == 0 {
		return words
	}

	// ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šè¯è¯­ç²˜è¿å¤„ç†
	// å°è¯•åˆå¹¶ç›¸é‚»çš„å•å­—è¯ä¸ºè¯ç»„
	words = o.mergeAdjacentChars(words)

	// ğŸ”¥ ç¬¬äºŒæ­¥ï¼šå•å­—è¯ä¼˜åŒ–
	// æ£€æŸ¥æ˜¯å¦æœ‰è¢«è¿‡åº¦åˆ‡åˆ†çš„æƒ…å†µ
	words = o.optimizeSingleChars(words)

	return words
}

// mergeAdjacentChars åˆå¹¶ç›¸é‚»çš„å•å­—ä¸ºè¯ç»„
// å¦‚æœè¿ç»­çš„å•å­—åœ¨è¯å…¸ä¸­å­˜åœ¨å¯¹åº”çš„è¯ç»„ï¼Œåˆ™åˆå¹¶
func (o *DictOptimizer) mergeAdjacentChars(words []tokenizer.Word) []tokenizer.Word {
	if len(words) < 2 {
		return words
	}

	result := make([]tokenizer.Word, 0, len(words))
	i := 0

	for i < len(words) {
		// å°è¯•ä»å½“å‰ä½ç½®å¼€å§‹æ‰¾æœ€é•¿çš„è¯ç»„åŒ¹é…
		maxLen := min(8, len(words)-i) // æœ€å¤§è¯ç»„é•¿åº¦ä¸º8
		merged := false

		// ä»æœ€é•¿åˆ°æœ€çŸ­å°è¯•åŒ¹é…
		for length := maxLen; length >= 2; length-- {
			if i+length > len(words) {
				continue
			}

			// åªåˆå¹¶å•å­—è¯æˆ–æœªè¯†åˆ«çš„è¯
			canMerge := true
			for j := 0; j < length; j++ {
				w := words[i+j]
				// å¦‚æœæ˜¯å·²è¯†åˆ«çš„ç‰¹æ®Šè¯ï¼ˆURLã€é‚®ç®±ã€äººåç­‰ï¼‰ï¼Œä¸å‚ä¸åˆå¹¶
				if w.P > 0 && w.P != postag.D_W {
					canMerge = false
					break
				}
				// å¦‚æœä¸æ˜¯å•å­—ï¼Œä¸å‚ä¸åˆå¹¶
				if len([]rune(w.W)) != 1 {
					canMerge = false
					break
				}
			}

			if !canMerge {
				break
			}

			// æ„å»ºå€™é€‰è¯ç»„
			var candidateText string
			for j := 0; j < length; j++ {
				candidateText += words[i+j].W
			}

			// æ£€æŸ¥è¯å…¸
			if dict.HasPhrase(candidateText) {
				// æ‰¾åˆ°è¯ç»„ï¼Œåˆå¹¶
				result = append(result, tokenizer.Word{
					W: candidateText,
					P: 0, // ä¿æŒæœªæ ‡æ³¨çŠ¶æ€ï¼Œå¯èƒ½åç»­ä¼šè¢«å…¶ä»–ä¼˜åŒ–å™¨è¯†åˆ«è¯æ€§
					C: words[i].C,
				})
				i += length
				merged = true
				break
			}
		}

		if !merged {
			// æ²¡æœ‰æ‰¾åˆ°åˆå¹¶æœºä¼šï¼Œä¿ç•™åŸè¯
			result = append(result, words[i])
			i++
		}
	}

	return result
}

// optimizeSingleChars ä¼˜åŒ–å•å­—è¯
// ä½¿ç”¨å¯å‘å¼è§„åˆ™æ”¹å–„åˆ†è¯ç»“æœ
func (o *DictOptimizer) optimizeSingleChars(words []tokenizer.Word) []tokenizer.Word {
	if len(words) < 2 {
		return words
	}

	result := make([]tokenizer.Word, 0, len(words))
	i := 0

	for i < len(words) {
		word := words[i]

		// ğŸ¯ è§„åˆ™1: æ•°è¯ + é‡è¯ â†’ ä¿æŒåˆ†ç¦»ï¼ˆç¬¦åˆè¯­æ³•ï¼‰
		if i < len(words)-1 {
			nextWord := words[i+1]

			// å¦‚æœå½“å‰æ˜¯æ•°è¯ï¼Œä¸‹ä¸€ä¸ªæ˜¯é‡è¯ï¼Œä¸åˆå¹¶
			if word.P == postag.A_M || isNumberWord(word.W) {
				if nextWord.P == postag.A_Q || isMeasureWord(nextWord.W) {
					result = append(result, word)
					i++
					continue
				}
			}
		}

		// ğŸ¯ è§„åˆ™2: è¿ç»­å•å­—è¯ä¸”åœ¨è¯å…¸ä¸­ â†’ å°è¯•åˆå¹¶
		if len([]rune(word.W)) == 1 && word.P == 0 {
			// å‘å‰çœ‹ï¼Œå°è¯•æ‰¾è¿ç»­çš„å•å­—
			j := i + 1
			for j < len(words) && len([]rune(words[j].W)) == 1 && words[j].P == 0 {
				j++
			}

			if j > i+1 {
				// æ‰¾åˆ°è¿ç»­å•å­—
				combinedText := ""
				for k := i; k < j; k++ {
					combinedText += words[k].W
				}

				// æ£€æŸ¥æ˜¯å¦åœ¨è¯å…¸ä¸­
				if dict.HasPhrase(combinedText) {
					result = append(result, tokenizer.Word{
						W: combinedText,
						P: 0,
						C: word.C,
					})
					i = j
					continue
				}
			}
		}

		// é»˜è®¤ï¼šä¿ç•™åŸè¯
		result = append(result, word)
		i++
	}

	return result
}

// isNumberWord åˆ¤æ–­æ˜¯å¦ä¸ºæ•°å­—è¯
func isNumberWord(word string) bool {
	numberWords := []string{
		"ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å",
		"ç™¾", "åƒ", "ä¸‡", "äº¿", "å…†",
		"é›¶", "å£¹", "è´°", "å", "è‚†", "ä¼", "é™†", "æŸ’", "æŒ", "ç–", "æ‹¾",
		"0", "1", "2", "3", "4", "5", "6", "7", "8", "9",
	}

	for _, num := range numberWords {
		if word == num {
			return true
		}
	}

	// æ£€æŸ¥æ˜¯å¦å…¨éƒ¨æ˜¯æ•°å­—
	for _, r := range word {
		if r < '0' || r > '9' {
			return false
		}
	}

	return len(word) > 0
}

// isMeasureWord åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¯
func isMeasureWord(word string) bool {
	measureWords := []string{
		"ä¸ª", "åª", "æ¡", "å¤´", "åŒ¹", "å³°", "å¼ ", "åº§", "å›", "åœº", "å°¾", "ä»¶",
		"æ”¯", "æ", "æ ¹", "æŠŠ", "å°", "è¾†", "ä½", "å", "å—", "ç‰‡", "æ®µ", "èŠ‚",
		"é¢—", "ç²’", "ç²’", "æ»´", "å›¢", "ä¸", "æ¯«", "å˜", "åˆ†", "å¯¸", "å°º", "ä¸ˆ",
		"é‡Œ", "æ–¤", "ä¸¤", "å…‹", "åƒå…‹", "å¨", "å‡", "æ¯«å‡", "ç±³", "åƒç±³",
		"å¹´", "æœˆ", "æ—¥", "æ—¶", "åˆ†", "ç§’", "å¤©", "å‘¨", "å­£", "å…ƒ", "è§’", "åˆ†",
		"æœ¬", "å†Œ", "å·", "ç¯‡", "ç« ", "é¡µ", "è¡Œ", "å¥", "æ®µ", "å­—", "åŒ", "å¯¹",
	}

	for _, measure := range measureWords {
		if word == measure {
			return true
		}
	}

	return false
}

// min è¿”å›ä¸¤ä¸ªæ•´æ•°ä¸­çš„æœ€å°å€¼
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// Name å®ç° Optimizer æ¥å£
func (o *DictOptimizer) Name() string {
	return "dict"
}
